# AI Engine Configuration

# Server Port
PORT=3001

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b

# Alternative Models (uncomment to use)
# OLLAMA_MODEL=llama3.2:3b
# OLLAMA_MODEL=llama3.2:10b
# OLLAMA_MODEL=mistral:7b
# OLLAMA_MODEL=codellama:13b
# OLLAMA_MODEL=phi3:medium

# Model Parameters
TEMPERATURE=0.7
TOP_P=0.9
MAX_TOKENS=2048
NUM_PREDICT=1024
